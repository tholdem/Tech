\documentclass[12pt]{article}
\input{../preamble.tex}

\begin{document}
\centerline {\textsf{\textbf{\LARGE{Midterm}}}}
\centerline {Jaden Wang}
\vspace{.15in}

\begin{problem}[1]
Let $ t>0$. First, we perform a change of variable so that we integrate from 0 to 1 to match the range of supremum. Let $ r = \frac{1}{t}s$, then $ dr = \frac{1}{t} ds$. Define  $ W_r :=  B_s^{\sqrt{t} } = \frac{1}{\sqrt{t} } B_{ts}$, then we have
\begin{align*}
	\int_{ 0}^{ t} \exp(B_s) \d s &= \int_{ 0}^{ 1} \exp(B_{ts}) t \d r \\
	&= t \int_{ 0}^{ 1} \exp \left( \sqrt{t} \frac{1}{\sqrt{t} }B_{ts}   \right)  \d r  \\
	&= t \int_{ 0}^{ 1} \exp \left( \sqrt{t} W_r  \right) \d r  .
\end{align*}
Denote $ \norm{ \cdot }_{\sqrt{t} } $ to be the $ L^{\sqrt{t}} ([0,1]) $-norm. Then we have
\begin{align*}
	\frac{1}{\sqrt{t} } \log \left( t \int_{ 0}^{ 1} \exp\left( \sqrt{t} W_r  \right) \d r  \right)& =   
	\frac{1}{\sqrt{t} } \log t + \frac{1}{\sqrt{t} } \log \left( \int_{ 0}^{ 1} \exp\left( \sqrt{t} W_r  \right) \d r  \right)\\
	&= \frac{\log t}{ \sqrt{t} } + \log \left( \left( \int_{ 0}^{ 1} \exp(W_r)^{ \sqrt{t} } \d r \right)^{\frac{1}{\sqrt{t} }}  \right)   \\
	&= \frac{\log t}{ \sqrt{t} } + \log \norm{ \exp (W_r)}_{\sqrt{t} }   .
\end{align*}
As $ t \to \infty$, the RHS becomes
\begin{align*}
	0 + \log \norm{ \exp(W_r)}_{ \infty} &= \log \sup_{r \in [0,1] } \exp(W_r)  \\
					     &= \sup_{r \in [0,1] } W_r  \\
					     & \sim \sup_{ r \in [0,1] } B_r   .
\end{align*}
where by scaling invariance of BM, $ W_r$ has the same distribution as  $ B_r$.
\end{problem}

\begin{problem}[2]
To show that $ (Y_t)$ does not satisfy the assumptions of the Kolmogorov continuity theorem, it suffices to show that the conclusion does not hold for  $ (Y_t)$, i.e.\  $ (Y_t)$ does not have a continuous modification. Suppose for a contradiction that $ (Y_t)$ has a continuous modification  $ (\widetilde{ Y}_t)$, this means $ Y_t = \widetilde{ Y}_t $ a.s.\ $\forall \ t \geq 0$ and $ \widetilde{ Y}_t( \omega)$ is continuous for any $ \omega \in \Omega$. Since $ \widetilde{ Y}_t$ can a.s.\ only take on values in the natural numbers, if we choose $ \epsilon = \frac{1}{2}$, then by continuity there exists a $ \delta>0$ such that whenever $ |t-s| < \delta$, we have $ \widetilde{ Y}_t = \widetilde{ Y}_s$ a.s. We wish to show that no such $ \delta$ exists, which would complete the contradiction.

Since $ (X_k)$ is a sequence of iid exponentially distributed r.v.\ with rate $ \lambda >0$, $ S_n$ has Gamma distribution $ \Gamma(n, \lambda)$. Let $ 0\leq s < t$, since $ (Y_t)$ is a Poisson process,  $ \mathbb{E}\left[ Y_t \right] = \lambda t < \infty$. Then we have
\begin{align*}
	\mathbb{E}\left[ \widetilde{ Y}_t - \widetilde{ Y}_s \right] &= \mathbb{E}\left[ \sum_{ n= 1}^{\infty} (\mathbbm{1}_{ \{S_n \leq t\} } - \mathbbm{1}_{\{S_n \leq s\}  })   \right]   \\
	&= \mathbb{E}\left[ \sum_{ n= 1}^{\infty} \mathbbm{1}_{ \{ s< S_n \leq t\}  }  \right]  \\
	&= \sum_{ n= 1}^{\infty} \mathbb{P}\left( s< S_n \leq t \right) && \textrm{ DCT}  \\
	& > 0 ,
\end{align*}
where the last inequality comes from that $ s<t$ and $ S_n$ has density function. This implies that $ \mathbb{P}\left( \widetilde{ Y}_t = \widetilde{ Y}_s \right) < 1$, because if they equal a.s.\ it would force their expectation difference to be 0. Therefore, no matter how small $ \delta>0$ is, there exists $ s<t$ such that $ |t-s|< \delta$ and $ \mathbb{P}\left(   \widetilde{ Y}_t = \widetilde{ Y}_s\right) < 1$. This concludes the proof. 
\end{problem}

\begin{problem}[3]
It suffices to show that the covariance function $ \Gamma(s, t) = \mathbbm{1}_{s=t } $ is symmetric and has positive type. Symmetry is clear. Given any $ c: T \to \rr$ with finite support,
\begin{align*}
	\sum_{s,t \in T} c(s) c(t) \Gamma(s, t) = \sum_{s,t \in T} c(s)c(t) \mathbbm{1}_{s=t } = \sum_{t \in T} c(t)^2 \geq 0.
\end{align*}
Thus, by the converse theorem, there exists a centered Gaussian process with this covariance function.

For a contradiction, suppose $ (X_t)$ has a jointly measurable modification $ (\widetilde{ X}_t)$, that is, $ (\omega,s) \mapsto \widetilde{ X}_s(\omega)$ is $ \mathcal{F} \otimes \mathcal{ B}([0,t]) $ for all $ t \geq 0$. Define $ Y_t = \int_{ 0}^{ t} \widetilde{ X}_s \d s $. Since $ \widetilde{ X}_t$ has finite moments, assumptions of Fubini are satisfied, and we have
\begin{align*}
	\mathbb{E}\left[ Y_t^2 \right] &= \mathbb{E}\left[ \int_{ 0}^{ t} \widetilde{ X}_s \d s \int_{ 0}^{ t} \widetilde{ X}_r \d r \right]  \\
				     &= \int_{ 0}^{ t} \int_{ 0}^{ t} \mathbb{E}\left[ \widetilde{ X}_s \widetilde{ X}_r \right] \d s \d r && \textrm{Fubini}    \\
				     &= \int_{ 0}^{ t} \int_{ 0}^{ t} \mathbbm{1}_{s=r } \d s \d r \\
				     &= \int_{ 0}^{ t} 0 \d r  \\
				     &= 0 .
\end{align*}
This implies that $ Y_t^2 = 0$ a.s.\ which implies $ \int_{ 0}^{ t} X_s \d s = 0$ a.s. Since this is true for any $ t\geq 0$, we must have  $ X_t = 0$ a.s. That is,  $ \mathbb{E}\left[ \int_{ 0}^{ t}  X_s^2 \d s \right] = 0 $. However, using Fubini we obtain
\begin{align*}
	\mathbb{E}\left[ \int_{ 0}^{ t}   X_s^2 \d s \right] &= \int_{ 0}^{ t} \mathbb{E}\left[ X_s^2 \right] \d s  \\
	&= \int_{ 0}^{ t} 1 \d s  = t ,
\end{align*}
a contradiction.
\end{problem}

\begin{problem}[4]
\begin{enumerate}[label=(\alph*)]
	\item We wish to use independent increment to get the bound with $ t$ in the exponent. To do that we need to discretize  $ t$. Let  $ n = \lfloor t \rfloor$. Consider $ B_k^{1} = B_{k+1} - B_k$ so $ |B_k^{1}| \leq |B_{k+1}| + |B_k|$ and $ B_k^{1} \sim N(0,1)$ is independent of $ B_k$. Then we have
\begin{align*}
	\mathbb{P}\left( U_1 \geq t \right) &= \mathbb{P}\left( \inf\{ t \geq 0: |B_t| =1 \}  \right)  \\
					    &= \mathbb{P}\left( |B_s| < 1 \ \forall \ s \in [0,t) \right)  \\
					    &\leq \mathbb{P}\left( |B_k| < 1 \ \forall \ 1\leq k \leq n \right)   \\
					    &\leq \mathbb{P}\left( |B_k^{1}| \leq |B_{k+1}| + |B_k| < 2 \ \forall \ 0 \leq k \leq n-1 \right)  \\
					    &= \mathbb{P}\left( |B_k^{1}| < 2 \right)^{n}  && \textrm{independence}  \\
					    &= \left(\int_{ -2}^{ 2} \frac{1}{\sqrt{2 \pi}} e^{-\frac{x^2}{2}} \d x \right)^{n}  .
\end{align*}
Since $ t \geq 1$ thus $ n\geq 1$, we can apply Jensen's inequality to move the exponent to the integrand:
 \begin{align*}
					    &\leq \int_{ -2}^{ 2} \frac{1}{\sqrt{2 \pi}^{n}} e^{-\frac{x^2n}{2}} \d x   \\
					    &< \int_{ -2}^{ 2} \frac{1}{\sqrt{2 \pi}^{n}} e^{-x^2t} \d x   ,
\end{align*}
as $ 1\leq \frac{t}{n}< 2$. Since $ e^{-x^2t}$ is exponential decay in $ t$, the integral is something like the average of exponential decay at different rates, therefore the RHS can be majorized by $ e^{-ct}$ for some $ c>0$. Thus, $ \mathbb{P}\left( U_1 \geq t \right) \leq e^{-ct}$. Then we have
\begin{align*}
	\mathbb{E}\left[ U_1^{p} \right] &= \int_{ 0}^{ \infty} t^{p} e^{-ct} \d t  \\
	&< \infty  ,
\end{align*}
since exponential decay dominates polynomial.
\item I feel like we could use similar strategy as above. The intuition is that $ B_t$ grows at the rate  $ \sqrt{t} $ so it should outgrows $ t^{\frac{1}{3}}$. The tricky thing is that now $ t$ would appear in the integration range, making it difficult to find a constant  $ c>0$. 
\end{enumerate}
\end{problem}
\end{document}
